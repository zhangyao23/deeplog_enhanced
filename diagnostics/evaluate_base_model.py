#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯Šæ–­è„šæœ¬ï¼šè¯„ä¼°åŸºç¡€æ¨¡å‹çš„æ•ˆæœ
"""

import sys
import os
import torch
import torch.nn as nn
import numpy as np
import logging
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.data_preprocessing import DataPreprocessor
from src.base_model import SimpleLSTM
from utils.data_utils import DataUtils

# --- æ—¥å¿—å’Œè®¾å¤‡é…ç½® ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def load_base_model(model_path):
    """æ ¹æ®ä¿å­˜çš„ä¿¡æ¯åŠ è½½æ­£ç¡®çš„æ¨¡å‹"""
    logging.info(f"ä» {model_path} åŠ è½½åŸºç¡€æ¨¡å‹...")
    checkpoint = torch.load(model_path, map_location=device)
    config = checkpoint['config']
    
    model_class = checkpoint.get('model_class')
    if model_class != 'SimpleLSTM':
        raise TypeError(f"æ­¤è¯„ä¼°è„šæœ¬ä¸“ä¸ºSimpleLSTMæ¨¡å‹è®¾è®¡ã€‚")
        
    num_event_types = config['data_config']['num_event_types']
    
    model = SimpleLSTM(
        input_size=1,
        hidden_size=64,
        num_layers=2,
        num_keys=num_event_types
    )
    
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()
    return model, config

def calculate_sequence_prediction_errors(model, preprocessor, config, sequences):
    """è®¡ç®—æ•´ä¸ªåºåˆ—çš„å¹³å‡é¢„æµ‹è¯¯å·®"""
    all_avg_errors = []
    
    preprocessor.logger.setLevel(logging.WARNING)
    
    pbar = tqdm(sequences, desc="è®¡ç®—åºåˆ—é¢„æµ‹è¯¯å·®")
    for seq in pbar:
        if not seq:
            all_avg_errors.append(0.0)
            continue
            
        mapped_seqs = preprocessor.apply_event_mapping([seq])
        inputs, targets = preprocessor.split_sequences(mapped_seqs, config['data_config']['window_size'])

        if len(inputs) == 0:
            all_avg_errors.append(0.0)
            continue

        inputs_tensor = torch.FloatTensor(inputs).to(device)
        targets_tensor = torch.LongTensor(targets).to(device)

        with torch.no_grad():
            seq_pred, _ = model(inputs_tensor)
            probs = torch.softmax(seq_pred, dim=1)
            
            # ç¡®ä¿targetsåœ¨åˆæ³•èŒƒå›´å†…
            valid_targets_mask = targets_tensor < seq_pred.shape[1]
            if not valid_targets_mask.all():
                logging.warning(f"å‘ç°è¶Šç•Œç›®æ ‡ç´¢å¼•ï¼Œå°†è·³è¿‡ã€‚åºåˆ—: {seq[:10]}...")
                targets_tensor = targets_tensor[valid_targets_mask]
                if targets_tensor.numel() == 0:
                    all_avg_errors.append(1.0) # å¦‚æœæ‰€æœ‰ç›®æ ‡éƒ½æ— æ•ˆï¼Œåˆ™è§†ä¸ºæœ€å¤§è¯¯å·®
                    continue

            target_probs = probs.gather(1, targets_tensor.unsqueeze(1)).squeeze()
            prediction_errors = (1 - target_probs).cpu().numpy()
        
        avg_error = np.mean(prediction_errors) if prediction_errors.size > 0 else 0.0
        all_avg_errors.append(avg_error)
        
    return np.array(all_avg_errors)

def plot_error_distribution(normal_errors, abnormal_errors, output_path):
    """ç»˜åˆ¶å¹¶ä¿å­˜è¯¯å·®åˆ†å¸ƒå›¾"""
    logging.info(f"ç»˜åˆ¶è¯¯å·®åˆ†å¸ƒå›¾å¹¶ä¿å­˜åˆ° {output_path}")
    plt.figure(figsize=(12, 7))
    sns.histplot(normal_errors, color="blue", label='Normal Sequences', kde=True, stat="density", element="step")
    sns.histplot(abnormal_errors, color="red", label='Abnormal Sequences', kde=True, stat="density", element="step")
    plt.title('Prediction Error Distribution (Base Model)', fontsize=16)
    plt.xlabel('Average Prediction Error', fontsize=12)
    plt.ylabel('Density', fontsize=12)
    plt.legend()
    plt.grid(True, which='both', linestyle='--', linewidth=0.5)
    plt.savefig(output_path)
    plt.close()
    logging.info("âœ… å›¾è¡¨ä¿å­˜æˆåŠŸã€‚")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Enhanced DeepLog - è¯Šæ–­ï¼šè¯„ä¼°åŸºç¡€æ¨¡å‹ ğŸš€")
    print("="*60)
    
    # --- åŠ è½½æ¨¡å‹å’Œé…ç½® ---
    model_path = 'enhanced_deeplog/models/base_model.pth'
    if not os.path.exists(model_path):
        logging.error("åŸºç¡€æ¨¡å‹ 'base_model.pth' æœªæ‰¾åˆ°. è¯·å…ˆè¿è¡Œ 01_train_base_model.pyã€‚")
        return
        
    model, config = load_base_model(model_path)
    
    # --- åŠ è½½æ•°æ® ---
    data_path = 'enhanced_deeplog/data/raw/synthetic_hdfs_train.txt'
    label_path = 'enhanced_deeplog/data/raw/synthetic_hdfs_train_labels.txt'
    with open(data_path, 'r') as f:
        all_sequences = [list(map(int, line.strip().split())) for line in f]
    with open(label_path, 'r') as f:
        all_labels = np.array([int(line.strip()) for line in f])

    # --- è®¡ç®—è¯¯å·® ---
    preprocessor = DataPreprocessor(config)
    preprocessor.event_mapping = config['event_mapping']
    
    all_errors = calculate_sequence_prediction_errors(model, preprocessor, config, all_sequences)
    
    normal_errors = all_errors[all_labels == 0]
    abnormal_errors = all_errors[all_labels != 0]

    # --- åˆ†æå’ŒæŠ¥å‘Š ---
    print("\n--- é¢„æµ‹è¯¯å·®ç»Ÿè®¡åˆ†æ ---")
    print(f"æ­£å¸¸åºåˆ— (å…± {len(normal_errors)} æ¡):")
    print(f"  - å¹³å‡è¯¯å·®: {np.mean(normal_errors):.4f}")
    print(f"  - ä¸­ä½æ•°è¯¯å·®: {np.median(normal_errors):.4f}")
    print(f"  - è¯¯å·®æ ‡å‡†å·®: {np.std(normal_errors):.4f}")
    print(f"  - æœ€å¤§è¯¯å·®: {np.max(normal_errors):.4f}\n")
    
    print(f"å¼‚å¸¸åºåˆ— (å…± {len(abnormal_errors)} æ¡):")
    print(f"  - å¹³å‡è¯¯å·®: {np.mean(abnormal_errors):.4f}")
    print(f"  - ä¸­ä½æ•°è¯¯å·®: {np.median(abnormal_errors):.4f}")
    print(f"  - è¯¯å·®æ ‡å‡†å·®: {np.std(abnormal_errors):.4f}")
    print(f"  - æœ€å°è¯¯å·®: {np.min(abnormal_errors):.4f}\n")
    
    # --- å¯è§†åŒ– ---
    output_dir = 'enhanced_deeplog/results'
    DataUtils.ensure_directory(output_dir)
    plot_path = os.path.join(output_dir, 'base_model_evaluation.png')
    plot_error_distribution(normal_errors, abnormal_errors, plot_path)
    
    print(f"ğŸ“ˆ è¯„ä¼°å›¾è¡¨å·²ä¿å­˜åˆ°: {plot_path}")
    print("="*60)

if __name__ == "__main__":
    main() 