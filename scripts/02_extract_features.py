#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é˜¶æ®µäºŒï¼šæå–å’Œé‡åŒ–â€œåå·®æ¨¡å¼â€
"""

import sys
import os
import torch
import numpy as np
import json
import logging
from tqdm import tqdm
from scipy import stats as scipy_stats
import torch.nn as nn

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

# å¯¼å…¥æœ¬åœ°æ¨¡å—
from enhanced_deeplog.src.data_preprocessing import DataPreprocessor
from enhanced_deeplog.src.feature_engineering import FeatureEngineer
from enhanced_deeplog.src.base_model import SimpleLSTM
from enhanced_deeplog.utils.data_utils import DataUtils

# é…ç½®æ—¥å¿—è®°å½•
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def get_config():
    """
    å®šä¹‰è„šæœ¬æ‰€éœ€çš„é…ç½®ã€‚
    """
    config = {
        "data_config": {
            "raw_data_dir": "enhanced_deeplog/data/raw",
            "processed_dir": "enhanced_deeplog/data/processed",
            "data_file": "synthetic_hdfs_train.txt",
            "labels_file": "synthetic_hdfs_train_labels.txt",
            "padding_value": 0,
            "window_size": 10,
            "max_sequence_length": 128,
            "min_sequence_length": 2
        },
        "feature_config": {
            "use_statistical_features": True,
            "use_prediction_features": True,
            "use_pattern_features": True
        },
        "model_config": {
            "base_model_path": "enhanced_deeplog/models/base_model.pth"
        }
    }
    return config

def load_base_model(model_path, device):
    """
    åŠ è½½è®­ç»ƒå¥½çš„SimpleLSTMåŸºç¡€æ¨¡å‹ã€‚
    """
    logging.info(f"ä» {model_path} åŠ è½½åŸºç¡€æ¨¡å‹...")
    checkpoint = torch.load(model_path, map_location=device)
    
    # ä»checkpointä¸­æ¢å¤configï¼Œç¡®ä¿ä¸€è‡´æ€§
    config = checkpoint['config']
    num_event_types = config['data_config']['num_event_types']

    model = SimpleLSTM(
        input_size=1,
        hidden_size=64,
        num_layers=2,
        num_keys=num_event_types
    )
    
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()
    return model, config, config.get('event_mapping', {})

def extract_features_for_all_sequences(config, model, preprocessor, feature_engineer, data_path, label_path):
    """ä¸ºæ‰€æœ‰åºåˆ—æå–ç‰¹å¾"""
    logging.info("ä¸ºæ‰€æœ‰åºåˆ—æå–ç‰¹å¾...")

    # åŠ è½½æ‰€æœ‰åŸå§‹æ•°æ®
    with open(data_path, 'r') as f:
        all_sequences = [list(map(int, line.strip().split())) for line in f]
    with open(label_path, 'r') as f:
        all_labels = [int(line.strip()) for line in f]

    final_features = []
    final_labels = []

    pbar = tqdm(zip(all_sequences, all_labels), total=len(all_sequences), desc="æå–ç‰¹å¾")
    for seq, label in pbar:
        if not seq: continue

        # 1. å¯¹å•ä¸ªåºåˆ—è¿›è¡Œæ»‘çª—å¤„ç†
        # é¢„å¤„ç†å™¨ç°åœ¨åŒ…å«äº†å…¨å±€çš„event_mapping
        mapped_seqs = preprocessor.apply_event_mapping([seq])
        inputs, targets = preprocessor.split_sequences(mapped_seqs, config['data_config']['window_size'])

        if len(inputs) == 0:
            continue

        # 2. è·å–åŸºç¡€æ¨¡å‹çš„é¢„æµ‹è¯¯å·®
        inputs_tensor = torch.FloatTensor(inputs).to(device)
        targets_tensor = torch.LongTensor(targets).to(device)

        with torch.no_grad():
            seq_pred, _ = model(inputs_tensor)
            probs = torch.softmax(seq_pred, dim=1)
            target_probs = probs.gather(1, targets_tensor.unsqueeze(1)).squeeze()
            prediction_errors = (1 - target_probs).cpu().numpy()

        # 3. èšåˆé¢„æµ‹è¯¯å·®ç‰¹å¾
        if prediction_errors.size == 0: continue
        
        # å¤„ç†å¯èƒ½çš„nan/infå€¼
        prediction_errors = prediction_errors[np.isfinite(prediction_errors)]
        if prediction_errors.size == 0: continue
        
        skewness = scipy_stats.skew(prediction_errors)
        kurtosis = scipy_stats.kurtosis(prediction_errors)

        pred_feats = np.array([
            np.mean(prediction_errors),
            np.std(prediction_errors),
            np.max(prediction_errors),
            np.min(prediction_errors),
            np.median(prediction_errors),
            skewness if np.isfinite(skewness) else 0,
            kurtosis if np.isfinite(kurtosis) else 0
        ])

        # 4. æå–ç»Ÿè®¡å’Œæ¨¡å¼ç‰¹å¾
        stat_feats = feature_engineer.extract_statistical_features([seq])[0]
        patt_feats = feature_engineer.extract_pattern_features([seq])[0]
        
        # 5. åˆå¹¶æ‰€æœ‰ç‰¹å¾
        combined_features = np.concatenate([pred_feats, stat_feats, patt_feats])
        
        final_features.append(combined_features)
        final_labels.append(label)

    return np.array(final_features), np.array(final_labels)

def main():
    """
    ä¸»å‡½æ•°ï¼Œæ‰§è¡Œç‰¹å¾æå–æµç¨‹ã€‚
    """
    print("ğŸš€ Enhanced DeepLog - é˜¶æ®µäºŒï¼šæå–å’Œé‡åŒ–â€œåå·®æ¨¡å¼â€ ğŸš€")
    print("="*60)
    
    # è·å–é…ç½®
    config = get_config()

    # æ£€æŸ¥è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logging.info(f"ä½¿ç”¨è®¾å¤‡: {device}")

    # åŠ è½½åŸºç¡€æ¨¡å‹
    base_model_path = config['model_config']['base_model_path']
    if not os.path.exists(base_model_path):
        logging.error(f"åŸºç¡€æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: {base_model_path}")
        logging.error("è¯·å…ˆè¿è¡Œ 01_train_base_model.py è„šæœ¬æ¥è®­ç»ƒå’Œä¿å­˜åŸºç¡€æ¨¡å‹ã€‚")
        return
    
    model, model_config, event_mapping = load_base_model(base_model_path, device)
    model.eval()

    # åˆå§‹åŒ–æ•°æ®é¢„å¤„ç†å™¨å’Œç‰¹å¾å·¥ç¨‹å¸ˆ
    preprocessor = DataPreprocessor(config)
    feature_engineer = FeatureEngineer(config, model, device, event_mapping)

    # åŠ è½½åŸå§‹æ•°æ®å’Œæ ‡ç­¾
    raw_data_path = os.path.join(config['data_config']['raw_data_dir'], config['data_config']['data_file'])
    labels_path = os.path.join(config['data_config']['raw_data_dir'], config['data_config']['labels_file'])
    
    if not os.path.exists(raw_data_path) or not os.path.exists(labels_path):
        logging.error(f"æ•°æ®æ–‡ä»¶æˆ–æ ‡ç­¾æ–‡ä»¶æœªæ‰¾åˆ°ã€‚è¯·ç¡®ä¿ {raw_data_path} å’Œ {labels_path} å­˜åœ¨ã€‚")
        logging.error("å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·è¿è¡Œ 00_generate_synthetic_data.py æ¥ç”Ÿæˆå®ƒä»¬ã€‚")
        return

    sequences = DataUtils.load_sequences(raw_data_path)
    labels = DataUtils.load_labels(labels_path)

    # æå–ç‰¹å¾
    all_features = []
    all_labels = []

    for i in tqdm(range(len(sequences)), desc="æå–ç‰¹å¾"):
        seq = sequences[i]
        label = labels[i]
        
        # é¢„å¤„ç†å•ä¸ªåºåˆ—ï¼ˆåˆ‡ç‰‡å’Œå¡«å……ï¼‰
        windows, _ = preprocessor.split_and_pad_sequence(seq, window_size=config['data_config']['window_size'])
        
        if windows.shape[0] == 0:
            continue
            
        # æå–ç‰¹å¾
        features = feature_engineer.extract_all_features(windows)
        
        all_features.append(features)
        # ä¸ºæ¯ä¸ªçª—å£åˆ†é…ç›¸åŒçš„åºåˆ—æ ‡ç­¾
        all_labels.extend([label] * features.shape[0])

    if not all_features:
        logging.error("æœªèƒ½ä»æ•°æ®ä¸­æå–ä»»ä½•ç‰¹å¾ã€‚è¯·æ£€æŸ¥è¾“å…¥æ•°æ®å’Œé…ç½®ã€‚")
        return

    features = np.vstack(all_features)
    labels = np.array(all_labels)
    
    logging.info(f"ç‰¹å¾æå–å®Œæˆã€‚ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {features.shape}, æ ‡ç­¾æ•°é‡: {len(labels)}")

    # ä¿å­˜ç‰¹å¾å’Œæ ‡ç­¾
    processed_dir = config['data_config']['processed_dir']
    DataUtils.ensure_directory(processed_dir)
    features_path = os.path.join(processed_dir, 'features.npy')
    labels_path = os.path.join(processed_dir, 'labels.npy')
    
    DataUtils.save_numpy_data(features, features_path)
    DataUtils.save_numpy_data(labels, labels_path)
    
    logging.info(f"âœ… ç‰¹å¾å·²ä¿å­˜åˆ° {features_path}")
    logging.info(f"âœ… æ ‡ç­¾å·²ä¿å­˜åˆ° {labels_path}")

if __name__ == "__main__":
    main() 