#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è„šæœ¬ 03: å¼‚å¸¸èšç±»

æ­¤è„šæœ¬æ‰§è¡Œ Enhanced DeepLog æ¨¡å‹çš„ç¬¬ä¸‰é˜¶æ®µï¼š
1. åŠ è½½ä»é˜¶æ®µäºŒæå–çš„ç‰¹å¾ã€‚
2. ä»…å¯¹å¼‚å¸¸æ ·æœ¬çš„ç‰¹å¾è¿›è¡Œèšç±»ï¼Œä»¥å‘ç°å¼‚å¸¸æ¨¡å¼çš„å†…åœ¨ç»“æ„ã€‚
3. ä½¿ç”¨ K-means æˆ– DBSCAN ç­‰ç®—æ³•å°†å¼‚å¸¸åˆ’åˆ†ä¸ºä¸åŒçš„ç°‡ã€‚
4. è¯„ä¼°èšç±»è´¨é‡ï¼Œå¹¶å°†èšç±»ç»“æœï¼ˆæ¨¡å‹å’Œæ ‡ç­¾ï¼‰ä¿å­˜åˆ°ç£ç›˜ï¼Œä»¥ä¾›é˜¶æ®µå››ä½¿ç”¨ã€‚
"""

import os
import sys
import logging
import numpy as np
import joblib

# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

from enhanced_deeplog.src.clustering import AnomalyClusterer
from enhanced_deeplog.utils.data_utils import DataUtils
from enhanced_deeplog.utils.evaluation import ModelEvaluator

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def main():
    """
    ä¸»å‡½æ•°ï¼Œæ‰§è¡Œå¼‚å¸¸èšç±»æµç¨‹ã€‚
    """
    print("ğŸš€ Enhanced DeepLog - é˜¶æ®µä¸‰ï¼šå¼‚å¸¸æ¨¡å¼èšç±» ğŸš€")
    print("="*60)

    # 1. åŠ è½½é…ç½®
    config_path = 'enhanced_deeplog/config/model_config.json'
    if not os.path.exists(config_path):
        logging.error(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")
        return
    config = DataUtils.load_config(config_path)
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    model_dir = os.path.dirname(config['model_config'].get('clustering_model_path', 'enhanced_deeplog/models/clustering_model.pkl'))
    DataUtils.ensure_directory(model_dir)

    # 2. åŠ è½½å¤„ç†å¥½çš„ç‰¹å¾å’Œæ ‡ç­¾
    features_path = os.path.join(config['data_config']['processed_dir'], 'features.npy')
    labels_path = os.path.join(config['data_config']['processed_dir'], 'labels.npy')

    if not os.path.exists(features_path) or not os.path.exists(labels_path):
        logging.error("ç‰¹å¾æˆ–æ ‡ç­¾æ–‡ä»¶æœªæ‰¾åˆ°ã€‚è¯·å…ˆè¿è¡Œ 02_extract_features.pyã€‚")
        return
    
    logging.info("åŠ è½½ç‰¹å¾å’Œæ ‡ç­¾...")
    features = DataUtils.load_numpy_data(features_path)
    labels = DataUtils.load_numpy_data(labels_path)

    # 3. ç­›é€‰å¼‚å¸¸ç‰¹å¾
    # æ ‡ç­¾ 0 é€šå¸¸æ˜¯æ­£å¸¸ï¼Œå¤§äº 0 æ˜¯ä¸åŒç±»å‹çš„å¼‚å¸¸
    anomaly_indices = np.where(labels > 0)[0]
    anomaly_features = features[anomaly_indices]
    original_anomaly_labels = labels[anomaly_indices]

    if len(anomaly_features) == 0:
        logging.warning("æ•°æ®ä¸­æœªå‘ç°å¼‚å¸¸ç‰¹å¾ï¼Œæ— æ³•è¿›è¡Œèšç±»ã€‚")
        return

    logging.info(f"æ‰¾åˆ°äº† {len(anomaly_features)} ä¸ªå¼‚å¸¸ç‰¹å¾æ ·æœ¬ç”¨äºèšç±»ã€‚")

    # 4. åˆå§‹åŒ–å¹¶æ‰§è¡Œèšç±»
    clusterer = AnomalyClusterer(config['clustering_config'])
    logging.info(f"ä½¿ç”¨ {config['clustering_config']['algorithm']} ç®—æ³•è¿›è¡Œèšç±»...")
    
    cluster_labels = clusterer.fit_predict(anomaly_features)
    
    # K-means èšç±»æ ‡ç­¾ä»0å¼€å§‹ï¼Œè€Œæˆ‘ä»¬çš„å¼‚å¸¸æ ‡ç­¾ä»1å¼€å§‹ã€‚
    # ä¸ºäº†ä¿æŒä¸€è‡´æ€§ï¼Œæˆ‘ä»¬å°†èšç±»æ ‡ç­¾åŠ 1ï¼Œä½¿å…¶ä»1å¼€å§‹ç¼–å·ã€‚
    cluster_labels += 1

    logging.info("èšç±»å®Œæˆã€‚")

    # 5. è¯„ä¼°èšç±»ç»“æœ
    evaluator = ModelEvaluator(config)
    clustering_report = evaluator.evaluate_clustering(anomaly_features, original_anomaly_labels, cluster_labels)
    
    print("\nğŸ“Š èšç±»è¯„ä¼°æŠ¥å‘Š ğŸ“Š")
    print("="*60)
    for metric, value in clustering_report.items():
        print(f"{metric}: {value:.4f}")
    print("="*60)
    
    # å¯è§†åŒ– (å¯é€‰ï¼Œä½†æ¨è)
    try:
        plot_path = os.path.join(os.path.dirname(config['data_config']['processed_dir']), 'diagnostics', 'clustering_visualization.png')
        DataUtils.ensure_directory(os.path.dirname(plot_path))
        evaluator.plot_clusters(anomaly_features, cluster_labels, title="å¼‚å¸¸ç‰¹å¾ T-SNE å¯è§†åŒ–", save_path=plot_path)
        logging.info(f"èšç±»å¯è§†åŒ–å›¾å·²ä¿å­˜åˆ°: {plot_path}")
    except Exception as e:
        logging.warning(f"æ— æ³•ç”Ÿæˆèšç±»å¯è§†åŒ–å›¾: {e}")


    # 6. ä¿å­˜èšç±»æ¨¡å‹å’Œæ–°çš„æ ‡ç­¾
    # åˆ›å»ºä¸€ä¸ªæ–°çš„æ ‡ç­¾æ•°ç»„ï¼Œå…¶ä¸­æ­£å¸¸æ ·æœ¬æ ‡ç­¾ä¸º0ï¼Œå¼‚å¸¸æ ·æœ¬æ ‡ç­¾ä¸ºèšç±»ç»“æœ
    final_labels = np.zeros_like(labels)
    final_labels[anomaly_indices] = cluster_labels
    
    # ä¿å­˜èšç±»æ¨¡å‹
    clustering_model_path = config['model_config'].get('clustering_model_path', 'enhanced_deeplog/models/clustering_model.pkl')
    joblib.dump(clusterer.model, clustering_model_path)
    logging.info(f"âœ… èšç±»æ¨¡å‹å·²ä¿å­˜åˆ°: {clustering_model_path}")

    # ä¿å­˜æœ€ç»ˆçš„æ ‡ç­¾
    final_labels_path = os.path.join(config['data_config']['processed_dir'], 'final_labels.npy')
    DataUtils.save_numpy_data(final_labels, final_labels_path)
    logging.info(f"âœ… æœ€ç»ˆæ ‡ç­¾ (èšç±»å) å·²ä¿å­˜åˆ°: {final_labels_path}")

    logging.info("ğŸ‰ é˜¶æ®µä¸‰å®Œæˆï¼ğŸ‰")


if __name__ == "__main__":
    main() 